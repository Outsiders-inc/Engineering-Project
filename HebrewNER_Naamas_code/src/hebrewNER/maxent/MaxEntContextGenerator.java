package hebrewNER.maxent;

import java.util.ArrayList;
import java.util.List;
import java.util.Map;
import java.util.Vector;

import opennlp.tools.util.*;
import opennlp.maxent.*;

import hebrewNER.util.*;

import vohmm.corpus.*;
import vohmm.util.*;
import vohmm.application.Tagger2;

   /**
   * Generates context to a token, given the sequence of sentence tokens
   * and additional context: POS tags and previous tags.<br>
   * Features: dictionary, word lists, regular expression, pos tags, lemma, prefix,
   * suffix, "smichut". Featurs are taken in a window of +-2 around current
   * token.<br>
   * The context generator is used for training by the event stream and by 
   * the name finder.
   */
public class MaxEntContextGenerator implements BeamSearchContextGenerator {
	
	
	private Dictionary dictionary,FWL;
	private Dictionary UBIMinus1,UBIPlus1;
	private Dictionary nouns, nounsMinus1, nounsPlus1;
	private Tagger2 posTagger;
	private RegExp regExp;
		
	
	public MaxEntContextGenerator(Tagger2 posTagger) {
		super();
		this.posTagger = posTagger;
		String dir = "lists";
		dictionary = Dictionary.getInstance(dir+"/Dictionary.txt");
		FWL = Dictionary.getInstance(dir+"/FWL.txt");
		UBIMinus1 = Dictionary.getInstance(dir+"/UBI-1.txt");
		UBIPlus1 = Dictionary.getInstance(dir+"/UBI+1.txt");
		nouns = Dictionary.getInstance(dir+"/Nouns.txt");
		nounsMinus1 = Dictionary.getInstance(dir+"/nouns-1.txt");
		nounsPlus1 = Dictionary.getInstance(dir+"/nouns+1.txt");
		regExp = RegExp.getInstance();
	}
	
	/**
  	 * Generate context for a sentence.
   	 * @param o   array of objects: index of current word, sequence of the sentence tokens,
   	 * sequence of previously predicted tags in the same sentence, pos analysis
   	 * and map of previously predicted tags and tokens.
   	 * @return The array of corresponding contexts generated by this context generator
   	 */	
	public String[] getContext(Object o) {
		Object[] data = (Object[]) o;
		if(data.length!=5){
			System.out.println("MaxEntContextGenerator: wrong additional context");
			System.exit(2);
		}
		List seq = (List) data[1];
		String[] toks = (String[]) seq.toArray(new String[seq.size()]);
		List predTags = ((Sequence) data[2]).getOutcomes();
		String[] preds = (String[]) predTags.toArray(new String[predTags.size()]);		 
		return (getContext(((Integer) data[0]).intValue(), toks, preds,
								(Sentence)data[3], (Map)data[4]));
	}	

	
	/**
  	 * Generate context for a sentence.
   	 * @param index   index of current word
   	 * @param sequence   sentence tokens 
   	 * @param s   previously predicted tags in the same sentence 
   	 * @param additionalContext   pos analysis and map of previously predicted tags and tokens.
   	 * @return The array of corresponding contexts generated by this context generator
   	 */	
	public String[] getContext(int index, List sequence, Sequence s, Object[] additionalContext) {
		if(additionalContext.length!=2){
			System.out.println("MaxEntContextGenerator: wrong additional context");
			System.exit(2);
		}
		String[] toks = (String[]) sequence.toArray(new String[sequence.size()]);
		List predTags = s.getOutcomes();
		String[] preds = (String[]) predTags.toArray(new String[predTags.size()]);		 
		return getContext(index, toks, preds, 
						   (Sentence)additionalContext[0], (Map)additionalContext[1]);
	}
	
	/**
  	 * Generate context for a sentence.
   	 * @param i   index of current word
   	 * @param toks   sentence tokens 
   	 * @param preds   previously predicted tags in the same sentence 
   	 * @param posAnal   pos analysis 
   	 * @param prevTags   map of previously predicted tags and tokens
   	 * @return The array of corresponding contexts generated by this context generator
   	 */	
  	public String[] getContext(int i, String[] toks, String[] preds, Sentence posAnal,
  								 Map prevTags) {
 		List feats = getStaticFeatures(toks,i,posAnal,prevTags);
 		String startFile="#f";
 		if(prevTags!=null && prevTags.size()==0)
 			startFile="#t";
 		feats.add("startFile="+startFile);
 		//predicted tags of ppw and pw
 		String po="null";
 		String ppo="null";
 		if (i > 1){
 			ppo = preds[i-2];
 		}
 		if (i > 0) {
 			po = preds[i-1];
 			Anal pwAnal = posAnal.getToken(i-1).getSelectedAnal();    			
    		long pwbitmask=pwAnal.getTag().getBitmask();
    		//smichut of previous word
    		String pwSmichut="#f";
 			if ((pwbitmask & Bitmask.BASEFORM_STATUS)== Bitmask.BASEFORM_STATUS_CONSTRUCT)
 				pwSmichut = "#t";
 			feats.add("pwSmichut="+pwSmichut);
 			feats.add("pwSmichut="+pwSmichut+",po="+po);
 		}
 		feats.add("po="+po);
 		feats.add("ppo="+ppo);
 		return (String[]) feats.toArray(new String[feats.size()]);
 	}
 	
 	private List getStaticFeatures(String[] toks, int i, Sentence posAnal, Map prevTags) {
 		List feats = new ArrayList();
 		feats.add("def");
 		
 		//current word
 		String w = toks[i];
 		feats.add("w=" + toks[i]);
 		String wf=TokenInfo.wordFeature(w);
 		feats.add("wf=" + wf);
 		String wd=dictionary.getDictionary(w);
 		feats.add("wd=" + wd);
 		feats.add("wRare=" + FWL.getDictionary(w));
 		feats.add("wNoun=" + nouns.getDictionary(w));
 		
 		//features taken from the pos tagger for current word
 		String wpos=null;
 		String smichut="#f";
 		Anal wAnal = posAnal.getToken(i).getSelectedAnal();
 		long  bitmask=wAnal.getTag().getBitmask();
 		wpos=Long.toString(bitmask & Bitmask.BASEFORM_POS);
 		feats.add("wpos="+wpos);
 		feats.add("w="+w+",wpos=" + wpos);
 		String wlemma=wAnal.getLemma().toString();
 		feats.add("wlemma="+wlemma);
 		feats.add("wpos=" + wpos + ",wlemma=" + wlemma);
 		feats.add("wprefix="+getPrefix(wAnal));
 		
		if (i == 0) feats.add("df=it");
	
 		//previous previous word
 		String ppw;
 		if (i - 2 >= 0) {
 			ppw = toks[i - 2];
 			feats.add("ppw=" + ppw);
 			feats.add("ppwf=" + TokenInfo.wordFeature(ppw));
 			feats.add("ppwpos="+getPOS(posAnal,i-2));
 		}
 		else {
 			ppw=null;
 			feats.add("ppw=BOS");
 		}
 		
 		// previous word
 		String pw;
 		if (i == 0) {
 			feats.add("pw=BOS");
 			pw=null;
 		}
 		else {
 			pw = toks[i - 1];
 			feats.add("pw=" + pw);
 			feats.add("pwf=" + TokenInfo.wordFeature(pw));
 			feats.add("pw=" + pw + ",w=" + w);
 			feats.add("wpwd=" + dictionary.getDictionary(pw+" "+w));
 			feats.add("pwUBI=" + UBIMinus1.getDictionary(pw));
 			feats.add("pwNoun=" + nounsMinus1.getDictionary(pw));
 			String pwpos=getPOS(posAnal,i-1);
 			feats.add("pwpos="+pwpos);
 			feats.add("w=" + w + ",pwpos=" + pwpos);
 			feats.add("wpos=" + wpos + ",pwpos=" + pwpos);
 		}
 	
 		//next word
 		String nw;
 		if (i + 1 >= toks.length) {
 			feats.add("nw=EOS");
 			nw=null;
 		}
 		else {
 			nw = toks[i + 1];
 			feats.add("nw=" + nw);
 			feats.add("nwf=" + TokenInfo.wordFeature(nw));
 			feats.add("w=" + w + ",nw=" + nw);
 			String wnwd=dictionary.getDictionary(w+" "+nw);
 			if(wnwd==null && pw!=null)
 				wnwd=dictionary.getDictionary(pw+" "+w+" "+nw);
 			feats.add("wnwd=" + wnwd);
 			feats.add("nwUBI=" + UBIPlus1.getDictionary(nw));
 			feats.add("nwNoun=" + nounsPlus1.getDictionary(nw));
 			feats.add("smichut=" + smichut + ",nw=" + nw);
 			String nwpos=getPOS(posAnal,i+1);
 			feats.add("nwpos="+nwpos);
 			feats.add("smichut=" + smichut + ",nwpos=" + nwpos);
 			feats.add("w=" + w + ",nwpos=" + nwpos);
 			feats.add("wpos=" + wpos + ",nwpos=" + nwpos);
 		}
 		
 		//next next word
 		String nnw;
 		if (i + 2 >= toks.length) {
 			feats.add("nnw=EOS");
 			nnw=null;
 		}
 		else {
 			nnw = toks[i + 2];
 			feats.add("nnw=" + nnw);
 			feats.add("nnwf=" + TokenInfo.wordFeature(nnw));
 			feats.add("nnwpos="+getPOS(posAnal,i+2));
 		}
 		
 		//checking for binary regular expressions	
 		feats.add("inCommas="+regExp.inCommas(toks,i));
 		
 		String isOrg=regExp.isOrg(ppw,pw,w,nw,nnw,wf);
		feats.add("isOrg=" +isOrg) ;
		feats.add("isOrg="+isOrg+",wpos=" + wpos);
 		
 		
 		String isLoc=regExp.isLoc(ppw,pw,w,nw,nnw);
		feats.add("isLoc=" + isLoc);
		feats.add("isLoc="+isLoc+",wpos=" + wpos);
		 		 		
 		String date=regExp.isDate(toks,i);
 		feats.add("date="+date);
 		feats.add("wf=" + wf + ",date=" + date);
 		 		
 		String percent=regExp.isPercent(pw,w,nw);
 		feats.add("percent=" + percent);
 		feats.add("wf=" + wf + ",percent=" + percent);
 		feats.add("wd=" + wd + ",percent=" + percent);
 		
 		String time=regExp.isTime(pw,w,nw);
 		feats.add("time="+time);
 		feats.add("wf=" + wf + ",time=" + time);
 		
 		String money=regExp.isMoney(ppw,pw,w,nw,nnw);
 		feats.add("money=" + money);
 		feats.add("wd=" + wd + ",money=" + money);
 		
 		//the dictionary entry of a long expression
 		feats.add("expDict=" + dictionary.getDictionary(ppw,pw,w,nw,nnw));
 				
 		return feats;
 	}
 	
 	//extracting the pos tag of token i from the analysis
 	private String getPOS(Sentence posAnal, int i){
 		Anal wAnal = posAnal.getToken(i).getSelectedAnal(); 
 		String wpos = Long.toString(wAnal.getTag().getBitmask() & Bitmask.BASEFORM_POS);
       	return wpos;
      }
    
   //extracting the prefix of from the analysis
   private String getPrefix(Anal wAnal){
    	String wprefix="#f";
    	if (wAnal.hasPrefix()){
    		Vector prefixes = wAnal.getPrefixes();
    		Affix prefix = posTagger.getAffix(((Integer)prefixes.get(0)).intValue());
 			wprefix = Long.toString(prefix.getBitmask());
    	}
    	return wprefix;
    }
    
    //extracting the suffix of from the analysis
    private String getSuffix(Anal wAnal){
    	String wsuffix="#f";
    	if (wAnal.hasSuffix())
    		wsuffix = Long.toString(posTagger.getAffix(wAnal.getSuffix()).getBitmask());
    	return wsuffix;
    }
 
}
